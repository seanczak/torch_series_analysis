{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from stacked_data import *\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While staggering the start point may be a good idea, I won't implement it inside the dataset object...\n",
    "\n",
    "Also only going to create the stacked dataset (as encode/decode is not particularly relevant for me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "https://pytorch.org/docs/stable/data.html#loading-batched-and-non-batched-data\n",
    "\n",
    "https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel\n",
    "\n",
    "he has a more sustainable solution that doesn't require you to have the full dataset in memory.  The way I would use this would be to make a folder called `data` and it would contain a csv for each sample series and then a metadata csv to hold onto the different parameters used to make each series (they could also be npy files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    '''Characterizes a dataset for PyTorch'''\n",
    "    def __init__(self, data):\n",
    "        'Initialization'\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.data.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data, these can then be concatenated by dataloader instance'\n",
    "\n",
    "        # Load data and get label\n",
    "        X = self.data.x[index]\n",
    "        y = self.data.y[index]\n",
    "\n",
    "        return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 1001), (100000,), torch.Size([100000, 497, 2]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from load_sines import *\n",
    "\n",
    "sin_data = stacked_univariant_data(sines, input_len=2,output_len=4,tau_offset=3)\n",
    "\n",
    "sines.shape, freqs.shape, sin_data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set = Dataset(sin_data)\n",
    "\n",
    "params = {'batch_size': 20102,\n",
    "          'shuffle': True,\n",
    "          'drop_last': False,\n",
    "          'num_workers': 11}\n",
    "\n",
    "training_generator = data.DataLoader(training_set, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20102, 497, 2]) torch.Size([20102, 497, 4])\n",
      "torch.Size([20102, 497, 2]) torch.Size([20102, 497, 4])\n",
      "torch.Size([20102, 497, 2]) torch.Size([20102, 497, 4])\n",
      "torch.Size([20102, 497, 2]) torch.Size([20102, 497, 4])\n",
      "torch.Size([19592, 497, 2]) torch.Size([19592, 497, 4])\n"
     ]
    }
   ],
   "source": [
    "for X,y in training_generator:\n",
    "    print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call this segmented or partitioned or isolated sequences... note that we no longer have to worry about overlapping.. in fact we want them to because it increases the amount of data the model sees (note that 1,2 would never have been seen before if input was 2 and we were stacking).. also we don't have to worry about staggering.  called segmented because the parent seq is segmented into many little ones\n",
    "\n",
    "also note that the first dimension is partially redundant if you don't care about keeping track of which parent seq each fragment comes from... if you want to get rid of it you can just say .reshape(-1,input_len) and similarly for the output. Why you'd want to keep it? Scoring. Why not? Training, you'd have to program with that extra dimension that means nothing (I suggest getting rid of it to train using the above and then putting it back with .reshape(batch_size,-1,output_len) at the end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_view(arr, window, axis=-1):\n",
    "    \"\"\"\n",
    "    return a running view of length 'window' over 'axis'\n",
    "    the returned array has an extra last dimension, which spans the window\n",
    "    \"\"\"\n",
    "    shape = list(arr.shape)\n",
    "    shape[axis] -= (window-1)\n",
    "    assert(shape[axis]>0)\n",
    "    return np.lib.index_tricks.as_strided(\n",
    "        arr,\n",
    "        shape + [window],\n",
    "        arr.strides + (arr.strides[axis],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = np.arange(40).reshape(-1,10)\n",
    "x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmented_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.],\n",
       "         [ 1.,  2.,  3.],\n",
       "         [ 2.,  3.,  4.],\n",
       "         [ 3.,  4.,  5.],\n",
       "         [ 4.,  5.,  6.],\n",
       "         [ 5.,  6.,  7.]],\n",
       "\n",
       "        [[10., 11., 12.],\n",
       "         [11., 12., 13.],\n",
       "         [12., 13., 14.],\n",
       "         [13., 14., 15.],\n",
       "         [14., 15., 16.],\n",
       "         [15., 16., 17.]],\n",
       "\n",
       "        [[20., 21., 22.],\n",
       "         [21., 22., 23.],\n",
       "         [22., 23., 24.],\n",
       "         [23., 24., 25.],\n",
       "         [24., 25., 26.],\n",
       "         [25., 26., 27.]],\n",
       "\n",
       "        [[30., 31., 32.],\n",
       "         [31., 32., 33.],\n",
       "         [32., 33., 34.],\n",
       "         [33., 34., 35.],\n",
       "         [34., 35., 36.],\n",
       "         [35., 36., 37.]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmented_univariant_data(x_t,input_len=3,output_len=2).x.reshape(-1,3).reshape(4,-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2],\n",
       "        [ 1,  2,  3],\n",
       "        [ 2,  3,  4],\n",
       "        [ 3,  4,  5],\n",
       "        [ 4,  5,  6],\n",
       "        [ 5,  6,  7],\n",
       "        [ 6,  7,  8],\n",
       "        [ 7,  8,  9]],\n",
       "\n",
       "       [[10, 11, 12],\n",
       "        [11, 12, 13],\n",
       "        [12, 13, 14],\n",
       "        [13, 14, 15],\n",
       "        [14, 15, 16],\n",
       "        [15, 16, 17],\n",
       "        [16, 17, 18],\n",
       "        [17, 18, 19]],\n",
       "\n",
       "       [[20, 21, 22],\n",
       "        [21, 22, 23],\n",
       "        [22, 23, 24],\n",
       "        [23, 24, 25],\n",
       "        [24, 25, 26],\n",
       "        [25, 26, 27],\n",
       "        [26, 27, 28],\n",
       "        [27, 28, 29]],\n",
       "\n",
       "       [[30, 31, 32],\n",
       "        [31, 32, 33],\n",
       "        [32, 33, 34],\n",
       "        [33, 34, 35],\n",
       "        [34, 35, 36],\n",
       "        [35, 36, 37],\n",
       "        [36, 37, 38],\n",
       "        [37, 38, 39]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_view(x_t,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
