{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create 2 channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.ones((2,15))\n",
    "data[1] += 1\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic 1d Conv\n",
    "\n",
    "Look at what the basic output looks like\n",
    "\n",
    "1 channel in and 1 channel out, and a kernel length of 5,\n",
    "\n",
    "no extra striding (stride =1), no extra padding (paadding = 0), no dilation (dilation =1)\n",
    "\n",
    "note that we are only required to give `in_channels, out_channels, kernel_size`. left the others there with their defaults (except bias, we're turning that off for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[-0.2142, -0.1719,  0.0711, -0.0663, -0.3345]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size =5,\n",
    "                        stride=1, padding=0, dilation=1, groups=1, bias=False, padding_mode='zeros')\n",
    "\n",
    "print(model.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets grab the first channel and add 2 dummy dimensions to it since that's what's expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 4., 1., 1., 1., 1., 1., 1., 1., 1., 1., 4.]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = data[0].view(1,1,-1)\n",
    "# inp[0,0,-1] = 4\n",
    "# inp[0,0,4] = 4\n",
    "inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass it into the model and see that it reduced the sequence length by 4 (we'll get to this when we talk about padding but just realize that only overlays the kernel over the sequence and not passed it, so the first value given is actually at the 3 index of the sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.7193, -0.9145, -0.5025, -1.2315, -1.3582, -0.7157, -0.7157,\n",
       "          -0.7157, -0.7157, -0.7157, -1.7193]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(inp)\n",
    "print(out.shape)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it's just $\\sum_{i=0}^k 1*w_i$ where $k$ is kernal length and $w_i$ refers to each weight. It's mult by 1 right now since our series is just ones [1,1,1....,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6312, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel is not a multiple of sequence length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[ 0.0741, -0.2244, -0.0752,  0.1084]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size =4,\n",
    "                        stride=1, padding=0, dilation=1, groups=1, bias=False, padding_mode='zeros')\n",
    "\n",
    "print(model.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again since the kernel is overlaid on top of the sequence, the first 3 values in the sequence don't have corresponding outputs from the model (since it is a requirement to have 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1170,  0.2081, -0.3425, -0.7901,  0.1054, -0.1170, -0.1170,\n",
       "          -0.1170, -0.1170, -0.1170, -0.1170,  0.2081]]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(inp)\n",
    "print(out.shape)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple inputs\n",
    "\n",
    "So what happens when we just change the number of input channels but still expect 1 channel in the output. We see that the weight tensor now has 2 kernels of length 5 (so the shape is (1,2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[ 0.2719,  0.1946, -0.3042,  0.1587, -0.1256],\n",
      "         [-0.1946,  0.0615, -0.1985, -0.1382,  0.2089]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Conv1d(in_channels = 2, out_channels = 1, kernel_size =5,\n",
    "                        stride=1, padding=0, dilation=1, groups=1, bias=False, padding_mode='zeros')\n",
    "\n",
    "print(model.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's grab both channels and add 2 dummy dimensions to the tensor since that's what's expected by torch (shape = (1,2,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = data.view(1,2,-1)\n",
    "inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass it into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6352, -0.6352, -0.6352, -0.6352, -0.6352, -0.6352, -0.6352,\n",
       "          -0.6352, -0.6352, -0.6352, -0.6352]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it's just $\\sum_{i=0}^k 1*w_i$ where $k$ is kernal length and $w_i$ refers to each weight. It's mult by 1 right now since our series is just ones [1,1,1....,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6312, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(1,1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stride is how many steps to take before making a new calculation (if you say 0 it will just stay in one spot and obviously kill the kernel you're working on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[-0.4267,  0.4077, -0.1108,  0.2961,  0.1737]]], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8097, 0.8097, 0.8097, 0.8097, 0.8097, 0.6989, 0.6989, 0.6989,\n",
       "          0.6989, 0.6989]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size =5,\n",
    "                stride=1, padding=0, dilation=2, groups=1, \n",
    "                bias=False, padding_mode='zeros')\n",
    "\n",
    "print(model.weight)\n",
    "model(a.view(1,1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4398, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight[0,0,1:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0668, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight[].sum()*2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3823)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([ 0.2745, -0.1809,  0.0806, -0.3044, -0.2521]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2890)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([ 0.2901,  0.1385, -0.2273, -0.1210,  0.2087]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19569999999999999"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.3823 + 0.2890*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9473)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0.0807,  0.1279, -0.1774, -0.0982, -0.0345]).sum() + 2 * torch.tensor([-0.0052,  0.0016,  0.1569,  0.2386,  0.1325]).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
